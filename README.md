# ğŸ¤– CodeGen AI Agent

An AI buddy that reads your docs, understands your code, and even writes new code for you.

---

## âœ¨ What It Does

- Reads your **API docs** (PDFs) like a champ  
- Peeks into your **code files** to understand whatâ€™s already there  
- Embeds all that knowledge into a searchable vector DB (fancy way of saying: *it remembers stuff*)  
- Takes natural language prompts like *â€œwrite me a Python script that calls the POST endpointâ€*  
- Gives clean JSON with:
  - `code` â†’ The actual Python code  
  - `description` â†’ What the code does in plain English  
  - `filename` â†’ Where itâ€™ll live  
- Saves everything neatly into an `output/` folder 

---

## Quickstart

1. **Clone this repo:**  
<pre>git clone https://github.com/<your-username>/codegen-ai-agent.git  
cd codegen-ai-agent</pre>

2. **Set up your virtual environment:**
<pre>python3 -m venv ai  
source ai/bin/activate</pre>  

3. **Install the magic sauce:**  
<pre>pip install -r requirements.txt  </pre>

4. **Add your api key to .env:**  
OLLAMA_API_KEY=your_api_key_here

5. **Run it:**   
<pre>python3 main.py</pre>

6. **Now you can talk to your AI Agent directly:**  
Enter a prompt (q to quit):  
â¡ read test.py and generate a new client script for the API

## ğŸ—‚ **Project Layout**
CODE_GEN_AGENT/
â”œâ”€ data/           # Drop your PDFs or code files here  
â”œâ”€ output/         # AI-generated code goes here  
â”œâ”€ main.py         # The brain  
â”œâ”€ prompts.py      # Custom prompts for the AI  
â”œâ”€ code_reader.py  # Lets AI actually read your code  
â””â”€ requirements.txt

## ğŸ›  **Built With**  
llama-index â€” for document + vector embeddings  
Ollama â€” local LLMs like mistral and codellama  
Pydantic â€” keeping JSON output squeaky clean
